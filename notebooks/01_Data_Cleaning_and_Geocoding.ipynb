{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "108029a2-3fc4-4915-ac39-ba518fa6534f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Libraries imported.\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('../data/processed', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "345582af-ae1b-4eb7-bc32-53129be29ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data. Original shape: (40160, 14)\n",
      "Column names standardized.\n"
     ]
    }
   ],
   "source": [
    "RAW_DATA_PATH = '../data/raw/crime_data.csv'\n",
    "\n",
    "# Verify the file exists\n",
    "if not os.path.exists(RAW_DATA_PATH):\n",
    "    print(f\"Error: File not found at {RAW_DATA_PATH}\")\n",
    "    print(\"Please make sure 'crime_data.csv' is in the 'data/raw/' folder.\")\n",
    "else:\n",
    "    df = pd.read_csv(RAW_DATA_PATH)\n",
    "    print(f\"Successfully loaded data. Original shape: {df.shape}\")\n",
    "    \n",
    "    # --- FIX: CLEAN COLUMN NAMES ---\n",
    "    \n",
    "    # 1. Strip whitespace from all column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # 2. Replace remaining spaces with underscores and convert to lowercase\n",
    "    # This ensures columns like 'Victim Age' become 'victim_age'\n",
    "    df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    print(\"Column names standardized.\")\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6175db54-93de-48be-a39c-41102d38cf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "Missing values handled.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40160 entries, 0 to 40159\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   report_number       40160 non-null  int64 \n",
      " 1   date_reported       40160 non-null  object\n",
      " 2   date_of_occurrence  40160 non-null  object\n",
      " 3   time_of_occurrence  40160 non-null  object\n",
      " 4   city                40160 non-null  object\n",
      " 5   crime_code          40160 non-null  int64 \n",
      " 6   crime_description   40160 non-null  object\n",
      " 7   victim_age          40160 non-null  int64 \n",
      " 8   victim_gender       40160 non-null  object\n",
      " 9   weapon_used         40160 non-null  object\n",
      " 10  crime_domain        40160 non-null  object\n",
      " 11  police_deployed     40160 non-null  int64 \n",
      " 12  case_closed         40160 non-null  object\n",
      " 13  date_case_closed    40160 non-null  object\n",
      "dtypes: int64(4), object(10)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Handling missing values...\")\n",
    "\n",
    "# Fill categorical NaNs\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "# Fill numerical NaNs\n",
    "# **UPDATED COLUMN NAMES:** 'Victim Age' -> 'victim_age', 'Police Deployed' -> 'police_deployed'\n",
    "num_cols = ['victim_age', 'police_deployed']\n",
    "for col in num_cols:\n",
    "    if col in df.columns:\n",
    "        median_val = df[col].median()\n",
    "        df[col] = df[col].fillna(median_val)\n",
    "        \n",
    "print(\"Missing values handled.\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdb0a482-d857-452d-9460-11d21bb0ac34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting geocoding... This will take a while.\n",
      "Found 29 unique cities to geocode.\n",
      "Geocoding API calls complete. Applying to DataFrame...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from geopy.exc import GeocoderUnavailable # Import necessary exception\n",
    "\n",
    "# Re-load the data and clean columns if you haven't run previous cells in this session\n",
    "# This ensures 'city' column exists and is clean\n",
    "# df = pd.read_csv('../data/raw/crime_data.csv')\n",
    "# df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "print(\"Starting geocoding... This will take a while.\")\n",
    "\n",
    "# Initialize Nominatim API with a longer timeout (10 seconds)\n",
    "geolocator = Nominatim(user_agent=\"geo-crime-predictor-v3\", timeout=10)\n",
    "\n",
    "# Increase the error_wait_seconds to 10 to give the server more time to recover from load\n",
    "# Removed 'max_tries' as it caused a TypeError\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1, error_wait_seconds=10)\n",
    "\n",
    "location_cache = {}\n",
    "\n",
    "# Get unique cities to minimize API calls (using the standardized 'city' column)\n",
    "unique_cities = df['city'].unique()\n",
    "print(f\"Found {len(unique_cities)} unique cities to geocode.\")\n",
    "\n",
    "for city in unique_cities:\n",
    "    if city == 'unknown':\n",
    "        location_cache[city] = (None, None)\n",
    "        continue\n",
    "    \n",
    "    query = f\"{city}, India\"\n",
    "    try:\n",
    "        # The RateLimiter handles the slow pace and retries here\n",
    "        location = geocode(query)\n",
    "        if location:\n",
    "            location_cache[city] = (location.latitude, location.longitude)\n",
    "        else:\n",
    "            # Prints a message for cities that couldn't be found\n",
    "            print(f\"Warning: Could not find location for '{city}'\")\n",
    "            location_cache[city] = (None, None)\n",
    "    except GeocoderUnavailable as e:\n",
    "        # This catches connection errors after all retries fail\n",
    "        print(f\"Critical Geocoding Error (Unavailable) for {city}: {e}\")\n",
    "        location_cache[city] = (None, None)\n",
    "    except Exception as e:\n",
    "        # Catch any other unexpected errors\n",
    "        print(f\"Critical Unexpected Error geocoding {city}: {e}\")\n",
    "        location_cache[city] = (None, None)\n",
    "\n",
    "print(\"Geocoding API calls complete. Applying to DataFrame...\")\n",
    "\n",
    "# Map the cached locations back to the DataFrame\n",
    "df['latitude'] = df['city'].map(lambda x: location_cache.get(x, (None, None))[0])\n",
    "df['longitude'] = df['city'].map(lambda x: location_cache.get(x, (None, None))[1])\n",
    "\n",
    "# Drop rows where geocoding failed\n",
    "original_rows = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b9483b2-0083-4b51-9afc-5b38b376a397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Final Feature Engineering and Encoding ---\n",
      "Categorical encoding complete. New columns added.\n",
      "Final processed DataFrame shape: (40160, 19)\n",
      "Final features: ['victim_age', 'police_deployed', 'latitude', 'longitude', 'report_hour', 'report_day_of_week', 'report_month', 'victim_gender_M', 'victim_gender_X', 'weapon_used_Explosives', 'weapon_used_Firearm', 'weapon_used_Knife', 'weapon_used_Other', 'weapon_used_Poison', 'weapon_used_Unknown', 'crime_domain_Other Crime', 'crime_domain_Traffic Fatality', 'crime_domain_Violent Crime', 'case_closed_Yes']\n",
      "\n",
      "--- Saving Processed Data ---\n",
      "Successfully saved processed data to: ../data/processed\\processed_crime_data.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Final Preprocessing: Feature Engineering and Encoding ---\n",
    "print(\"\\n--- Starting Final Feature Engineering and Encoding ---\")\n",
    "\n",
    "# 1. Feature Engineering: Extracting Time Features from 'date_reported'\n",
    "# We will use the 'date_reported' column as a proxy for the incident's date/time context.\n",
    "df['date_reported'] = pd.to_datetime(df['date_reported'], format='%m-%d-%Y %H:%M', errors='coerce')\n",
    "\n",
    "df['report_hour'] = df['date_reported'].dt.hour\n",
    "df['report_day_of_week'] = df['date_reported'].dt.dayofweek\n",
    "df['report_month'] = df['date_reported'].dt.month\n",
    "\n",
    "# 2. Categorical Encoding (One-Hot Encoding)\n",
    "# We need to convert our main categorical features into numerical format.\n",
    "categorical_cols = ['victim_gender', 'weapon_used', 'crime_domain', 'case_closed']\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True, prefix=categorical_cols)\n",
    "\n",
    "print(\"Categorical encoding complete. New columns added.\")\n",
    "\n",
    "# 3. Dropping Redundant Columns\n",
    "# Drop original columns that are now redundant or not useful for the model.\n",
    "columns_to_drop = [\n",
    "    'report_number',        # Unique ID, not a feature\n",
    "    'date_reported',        # Extracted features from this\n",
    "    'date_of_occurrence',   # Too complex/redundant with 'date_reported' for simple model\n",
    "    'time_of_occurrence',   # Not consistent and too noisy\n",
    "    'city',                 # Replaced by Latitude/Longitude\n",
    "    'crime_code',           # Replaced by 'crime_description'\n",
    "    'crime_description',    # The target variable (will be handled in the next notebook)\n",
    "    'date_case_closed',     # Not directly predictive of the crime itself\n",
    "]\n",
    "\n",
    "df_processed = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Rename the geocoded columns for consistency (already done in my previous response, but confirming here)\n",
    "df_processed = df_processed.rename(columns={'Latitude': 'latitude', 'Longitude': 'longitude'})\n",
    "\n",
    "# Display final feature set and shape\n",
    "print(f\"Final processed DataFrame shape: {df_processed.shape}\")\n",
    "print(f\"Final features: {df_processed.columns.tolist()}\")\n",
    "\n",
    "# --- Saving Processed Data ---\n",
    "print(\"\\n--- Saving Processed Data ---\")\n",
    "\n",
    "# Create the data/processed directory if it doesn't exist\n",
    "output_dir = '../data/processed'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Define the output file path\n",
    "output_file = os.path.join(output_dir, 'processed_crime_data.csv')\n",
    "\n",
    "# Save the processed DataFrame\n",
    "df_processed.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Successfully saved processed data to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
